{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tratamento de Dados.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EXp5nqmN81g9",
        "colab_type": "text"
      },
      "source": [
        "#Tratamento de Dados"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xC_So-_p9OOt",
        "colab_type": "text"
      },
      "source": [
        "Neste caderno aplicaremos a técnicas de tratamento de dados para os casos em que os dados apresentem valores ausentes e variáveis categóricas.\n",
        "\n",
        "Materiais de Referência: https://www.kaggle.com/alexisbcook/missing-values\n",
        "\n",
        "https://www.kaggle.com/alexisbcook/categorical-variables"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rb4M4Qm5-iw0",
        "colab_type": "text"
      },
      "source": [
        "## Valores Ausentes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bykv5Yq6-8CS",
        "colab_type": "text"
      },
      "source": [
        "No exemplo, trabalharemos com o conjunto de dados __[Melbourne Housing dataset](https://www.kaggle.com/dansbecker/melbourne-housing-snapshot/home)__. Nosso modelo usarEMOS informações como o número de quartos e o tamanho da terra para prever o preço da casa.\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "> Não vamos nos concentrar na etapa de carregamento de dados. Em vez disso, você pode imaginar que já está com os dados de treinamento e validação em X_train, X_valid, y_train e y_valid."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jtIdpwDy9Lgg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 660
        },
        "outputId": "35fca0ca-dcd5-44d7-9c63-cd67a1886adc"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "data = pd.read_csv('melb_data.csv')\n",
        "\n",
        "# Saída do preditor\n",
        "y = data.Price\n",
        "\n",
        "# Usaremos apenas preditores numéricos\n",
        "melb_predictors = data.drop(['Price'], axis=1)\n",
        "X = melb_predictors.select_dtypes(exclude=['object'])\n",
        "\n",
        "# Divide os dados em subconjuntos de treinamento e validação\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X, y, train_size=0.8, test_size=0.2,\n",
        "                                                      random_state=0)\n",
        "\n",
        "data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Suburb</th>\n",
              "      <th>Address</th>\n",
              "      <th>Rooms</th>\n",
              "      <th>Type</th>\n",
              "      <th>Price</th>\n",
              "      <th>Method</th>\n",
              "      <th>SellerG</th>\n",
              "      <th>Date</th>\n",
              "      <th>Distance</th>\n",
              "      <th>Postcode</th>\n",
              "      <th>Bedroom2</th>\n",
              "      <th>Bathroom</th>\n",
              "      <th>Car</th>\n",
              "      <th>Landsize</th>\n",
              "      <th>BuildingArea</th>\n",
              "      <th>YearBuilt</th>\n",
              "      <th>CouncilArea</th>\n",
              "      <th>Lattitude</th>\n",
              "      <th>Longtitude</th>\n",
              "      <th>Regionname</th>\n",
              "      <th>Propertycount</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Abbotsford</td>\n",
              "      <td>85 Turner St</td>\n",
              "      <td>2</td>\n",
              "      <td>h</td>\n",
              "      <td>1480000.0</td>\n",
              "      <td>S</td>\n",
              "      <td>Biggin</td>\n",
              "      <td>3/12/2016</td>\n",
              "      <td>2.5</td>\n",
              "      <td>3067.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>202.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Yarra</td>\n",
              "      <td>-37.79960</td>\n",
              "      <td>144.99840</td>\n",
              "      <td>Northern Metropolitan</td>\n",
              "      <td>4019.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Abbotsford</td>\n",
              "      <td>25 Bloomburg St</td>\n",
              "      <td>2</td>\n",
              "      <td>h</td>\n",
              "      <td>1035000.0</td>\n",
              "      <td>S</td>\n",
              "      <td>Biggin</td>\n",
              "      <td>4/02/2016</td>\n",
              "      <td>2.5</td>\n",
              "      <td>3067.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>156.0</td>\n",
              "      <td>79.0</td>\n",
              "      <td>1900.0</td>\n",
              "      <td>Yarra</td>\n",
              "      <td>-37.80790</td>\n",
              "      <td>144.99340</td>\n",
              "      <td>Northern Metropolitan</td>\n",
              "      <td>4019.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Abbotsford</td>\n",
              "      <td>5 Charles St</td>\n",
              "      <td>3</td>\n",
              "      <td>h</td>\n",
              "      <td>1465000.0</td>\n",
              "      <td>SP</td>\n",
              "      <td>Biggin</td>\n",
              "      <td>4/03/2017</td>\n",
              "      <td>2.5</td>\n",
              "      <td>3067.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>134.0</td>\n",
              "      <td>150.0</td>\n",
              "      <td>1900.0</td>\n",
              "      <td>Yarra</td>\n",
              "      <td>-37.80930</td>\n",
              "      <td>144.99440</td>\n",
              "      <td>Northern Metropolitan</td>\n",
              "      <td>4019.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Abbotsford</td>\n",
              "      <td>40 Federation La</td>\n",
              "      <td>3</td>\n",
              "      <td>h</td>\n",
              "      <td>850000.0</td>\n",
              "      <td>PI</td>\n",
              "      <td>Biggin</td>\n",
              "      <td>4/03/2017</td>\n",
              "      <td>2.5</td>\n",
              "      <td>3067.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>94.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Yarra</td>\n",
              "      <td>-37.79690</td>\n",
              "      <td>144.99690</td>\n",
              "      <td>Northern Metropolitan</td>\n",
              "      <td>4019.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Abbotsford</td>\n",
              "      <td>55a Park St</td>\n",
              "      <td>4</td>\n",
              "      <td>h</td>\n",
              "      <td>1600000.0</td>\n",
              "      <td>VB</td>\n",
              "      <td>Nelson</td>\n",
              "      <td>4/06/2016</td>\n",
              "      <td>2.5</td>\n",
              "      <td>3067.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>120.0</td>\n",
              "      <td>142.0</td>\n",
              "      <td>2014.0</td>\n",
              "      <td>Yarra</td>\n",
              "      <td>-37.80720</td>\n",
              "      <td>144.99410</td>\n",
              "      <td>Northern Metropolitan</td>\n",
              "      <td>4019.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13575</th>\n",
              "      <td>Wheelers Hill</td>\n",
              "      <td>12 Strada Cr</td>\n",
              "      <td>4</td>\n",
              "      <td>h</td>\n",
              "      <td>1245000.0</td>\n",
              "      <td>S</td>\n",
              "      <td>Barry</td>\n",
              "      <td>26/08/2017</td>\n",
              "      <td>16.7</td>\n",
              "      <td>3150.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>652.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1981.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-37.90562</td>\n",
              "      <td>145.16761</td>\n",
              "      <td>South-Eastern Metropolitan</td>\n",
              "      <td>7392.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13576</th>\n",
              "      <td>Williamstown</td>\n",
              "      <td>77 Merrett Dr</td>\n",
              "      <td>3</td>\n",
              "      <td>h</td>\n",
              "      <td>1031000.0</td>\n",
              "      <td>SP</td>\n",
              "      <td>Williams</td>\n",
              "      <td>26/08/2017</td>\n",
              "      <td>6.8</td>\n",
              "      <td>3016.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>333.0</td>\n",
              "      <td>133.0</td>\n",
              "      <td>1995.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-37.85927</td>\n",
              "      <td>144.87904</td>\n",
              "      <td>Western Metropolitan</td>\n",
              "      <td>6380.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13577</th>\n",
              "      <td>Williamstown</td>\n",
              "      <td>83 Power St</td>\n",
              "      <td>3</td>\n",
              "      <td>h</td>\n",
              "      <td>1170000.0</td>\n",
              "      <td>S</td>\n",
              "      <td>Raine</td>\n",
              "      <td>26/08/2017</td>\n",
              "      <td>6.8</td>\n",
              "      <td>3016.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>436.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1997.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-37.85274</td>\n",
              "      <td>144.88738</td>\n",
              "      <td>Western Metropolitan</td>\n",
              "      <td>6380.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13578</th>\n",
              "      <td>Williamstown</td>\n",
              "      <td>96 Verdon St</td>\n",
              "      <td>4</td>\n",
              "      <td>h</td>\n",
              "      <td>2500000.0</td>\n",
              "      <td>PI</td>\n",
              "      <td>Sweeney</td>\n",
              "      <td>26/08/2017</td>\n",
              "      <td>6.8</td>\n",
              "      <td>3016.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>866.0</td>\n",
              "      <td>157.0</td>\n",
              "      <td>1920.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-37.85908</td>\n",
              "      <td>144.89299</td>\n",
              "      <td>Western Metropolitan</td>\n",
              "      <td>6380.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13579</th>\n",
              "      <td>Yarraville</td>\n",
              "      <td>6 Agnes St</td>\n",
              "      <td>4</td>\n",
              "      <td>h</td>\n",
              "      <td>1285000.0</td>\n",
              "      <td>SP</td>\n",
              "      <td>Village</td>\n",
              "      <td>26/08/2017</td>\n",
              "      <td>6.3</td>\n",
              "      <td>3013.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>362.0</td>\n",
              "      <td>112.0</td>\n",
              "      <td>1920.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-37.81188</td>\n",
              "      <td>144.88449</td>\n",
              "      <td>Western Metropolitan</td>\n",
              "      <td>6543.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>13580 rows × 21 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "              Suburb  ... Propertycount\n",
              "0         Abbotsford  ...        4019.0\n",
              "1         Abbotsford  ...        4019.0\n",
              "2         Abbotsford  ...        4019.0\n",
              "3         Abbotsford  ...        4019.0\n",
              "4         Abbotsford  ...        4019.0\n",
              "...              ...  ...           ...\n",
              "13575  Wheelers Hill  ...        7392.0\n",
              "13576   Williamstown  ...        6380.0\n",
              "13577   Williamstown  ...        6380.0\n",
              "13578   Williamstown  ...        6380.0\n",
              "13579     Yarraville  ...        6543.0\n",
              "\n",
              "[13580 rows x 21 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wOiuk2jcJN97",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "9272d80a-390c-4ef0-bb91-84ce7061ac4e"
      },
      "source": [
        "# Forma dos dados de treinamento (num_rows, num_columns)\n",
        "print(X_train.shape)\n",
        "\n",
        "# Número de valores ausentes em cada coluna de dados de treinamento\n",
        "missing_val_count_by_column = (X_train.isnull().sum())\n",
        "print(missing_val_count_by_column[missing_val_count_by_column > 0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10864, 12)\n",
            "Car               49\n",
            "BuildingArea    5156\n",
            "YearBuilt       4307\n",
            "dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sw-ue3H8B0bS",
        "colab_type": "text"
      },
      "source": [
        "### Definir função para medir a qualidade de cada abordagem\n",
        "Definimos uma função *score_dataset()* para comparar diferentes abordagens para lidar com valores ausentes. Esta função relata o **erro absoluto médio (MAE)** de um modelo de floresta aleatório."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SaF4vt-YBmqS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "# Function for comparing different approaches\n",
        "def score_dataset(X_train, X_valid, y_train, y_valid):\n",
        "    model = RandomForestRegressor(n_estimators=10, random_state=0)\n",
        "    model.fit(X_train, y_train)\n",
        "    preds = model.predict(X_valid)\n",
        "    return mean_absolute_error(y_valid, preds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j-nc1N5OCpoE",
        "colab_type": "text"
      },
      "source": [
        "### 1) Eliminando colunas com valores ausentes\n",
        "Como estamos trabalhando com conjuntos de **treinamento e validação**, tomamos o cuidado de **eliminar as mesmas colunas nos dois DataFrames**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "da_ivzgEChmk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "e326a9b4-8869-42f2-8e63-7e81e76a7f31"
      },
      "source": [
        "# Obter nomes de colunas com valores ausentes\n",
        "cols_with_missing = [col for col in X_train.columns\n",
        "                     if X_train[col].isnull().any()]\n",
        "\n",
        "# Eliminar colunas nos dados de treinamento e validação\n",
        "reduced_X_train = X_train.drop(cols_with_missing, axis=1)\n",
        "reduced_X_valid = X_valid.drop(cols_with_missing, axis=1)\n",
        "\n",
        "print(\"MAE da Abordagem 1 (Eliminar colunas com valores ausentes):\")\n",
        "print(score_dataset(reduced_X_train, reduced_X_valid, y_train, y_valid))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MAE da Abordagem 1 (Eliminar colunas com valores ausentes):\n",
            "183550.22137772635\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bj7Sd9xYDe1y",
        "colab_type": "text"
      },
      "source": [
        "### 2) Imputação\n",
        "Em seguida, usamos o *SimpleImputer* para substituir os valores ausentes pelo **valor médio em cada coluna**.\n",
        "\n",
        "Embora seja simples, o preenchimento do valor médio geralmente funciona muito bem (mas isso varia de acordo com o conjunto de dados). Embora os estatísticos tenham experimentado maneiras mais complexas de determinar valores imputados (como imputação de regressão, por exemplo), **as estratégias complexas geralmente não oferecem benefícios adicionais depois que você conecta os resultados a modelos sofisticados de aprendizado de máquina**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qJ2ARHKnDviG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "7d655632-b189-40eb-a7e1-b5c3718f65c7"
      },
      "source": [
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# Imputação\n",
        "my_imputer = SimpleImputer()\n",
        "imputed_X_train = pd.DataFrame(my_imputer.fit_transform(X_train))\n",
        "imputed_X_valid = pd.DataFrame(my_imputer.transform(X_valid))\n",
        "\n",
        "# Imputação removida de nomes de colunas; colocá-los de volta\n",
        "imputed_X_train.columns = X_train.columns\n",
        "imputed_X_valid.columns = X_valid.columns\n",
        "\n",
        "print(\"MAE da Abordagem 2 (Imputação):\")\n",
        "print(score_dataset(imputed_X_train, imputed_X_valid, y_train, y_valid))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MAE da Abordagem 2 (Imputação):\n",
            "178166.46269899711\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ihCkOp-DewP",
        "colab_type": "text"
      },
      "source": [
        "Vemos que a Abordagem 2 tem MAE menor que a Abordagem 1, portanto, a Abordagem 2 teve um desempenho melhor nesse conjunto de dados.\n",
        "\n",
        "### 3) uma extensão à imputação\n",
        "Em seguida, imputamos os valores ausentes, além de acompanharmos quais valores foram imputados."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cpnma94NE_dk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "5f7880f1-85e5-4c75-ab82-968fcf1c5ee6"
      },
      "source": [
        "# Faz uma cópia para evitar a alteração de dados originais (ao imputar)\n",
        "X_train_plus = X_train.copy()\n",
        "X_valid_plus = X_valid.copy()\n",
        "\n",
        "# Faz novas colunas indicando o que será imputado\n",
        "for col in cols_with_missing:\n",
        "    X_train_plus[col + '_was_missing'] = X_train_plus[col].isnull()\n",
        "    X_valid_plus[col + '_was_missing'] = X_valid_plus[col].isnull()\n",
        "\n",
        "# Imputação\n",
        "my_imputer = SimpleImputer()\n",
        "imputed_X_train_plus = pd.DataFrame(my_imputer.fit_transform(X_train_plus))\n",
        "imputed_X_valid_plus = pd.DataFrame(my_imputer.transform(X_valid_plus))\n",
        "\n",
        "# Imputação removida de nomes de colunas; colocá-los de volta\n",
        "imputed_X_train_plus.columns = X_train_plus.columns\n",
        "imputed_X_valid_plus.columns = X_valid_plus.columns\n",
        "\n",
        "print(\"MAE from Approach 3 (An Extension to Imputation):\")\n",
        "print(score_dataset(imputed_X_train_plus, imputed_X_valid_plus, y_train, y_valid))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MAE from Approach 3 (An Extension to Imputation):\n",
            "178927.503183954\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SNxTvqZhIea4",
        "colab_type": "text"
      },
      "source": [
        "Como podemos ver, a abordagem 3 teve um desempenho um pouco pior que a abordagem 2.\n",
        "\n",
        "### Então, por que a imputação teve um desempenho melhor do que elimiar as colunas?\n",
        ">\n",
        "> Os dados de treinamento possuem 10864 linhas e 12 colunas, nas quais três colunas contêm dados ausentes. Para cada coluna, **menos da metade das entradas está ausente**. Assim, a eliminação das colunas remove muitas informações úteis e, portanto, faz sentido que a imputação tenha um desempenho melhor."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AatAabnq89q7",
        "colab_type": "text"
      },
      "source": [
        "## Variáveis Categóricas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NCR6ErZ7LWOR",
        "colab_type": "text"
      },
      "source": [
        "Como no tutorial anterior, trabalharemos com o conjunto de dados __[Melbourne Housing dataset](https://www.kaggle.com/dansbecker/melbourne-housing-snapshot/home)__.\n",
        "\n",
        "Não vamos nos concentrar na etapa de carregamento de dados. Em vez disso, você pode imaginar que já está com os dados de treinamento e validação em X_train, X_valid, y_train e y_valid."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IGQnjBqeND0S",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "85cd73f3-caf6-4bce-a53a-bcc938130d6b"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Read the data\n",
        "data = pd.read_csv('melb_data.csv')\n",
        "\n",
        "# Separate target from predictors\n",
        "y = data.Price\n",
        "X = data.drop(['Price'], axis=1)\n",
        "\n",
        "# Divide data into training and validation subsets\n",
        "X_train_full, X_valid_full, y_train, y_valid = train_test_split(X, y, train_size=0.8, test_size=0.2,\n",
        "                                                                random_state=0)\n",
        "\n",
        "# Drop columns with missing values (simplest approach)\n",
        "cols_with_missing = [col for col in X_train_full.columns if X_train_full[col].isnull().any()] \n",
        "X_train_full.drop(cols_with_missing, axis=1, inplace=True)\n",
        "X_valid_full.drop(cols_with_missing, axis=1, inplace=True)\n",
        "\n",
        "# \"Cardinality\" means the number of unique values in a column\n",
        "# Select categorical columns with relatively low cardinality (convenient but arbitrary)\n",
        "low_cardinality_cols = [cname for cname in X_train_full.columns if X_train_full[cname].nunique() < 10 and \n",
        "                        X_train_full[cname].dtype == \"object\"]\n",
        "\n",
        "# Select numerical columns\n",
        "numerical_cols = [cname for cname in X_train_full.columns if X_train_full[cname].dtype in ['int64', 'float64']]\n",
        "\n",
        "# Keep selected columns only\n",
        "my_cols = low_cardinality_cols + numerical_cols\n",
        "X_train = X_train_full[my_cols].copy()\n",
        "X_valid = X_valid_full[my_cols].copy()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py:3997: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  errors=errors,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e-XO8rWLNLzH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        },
        "outputId": "4c6344e8-a29d-4022-ffe5-8241424fdc9f"
      },
      "source": [
        "#Exibição dos dados de treinamento\n",
        "X_train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Type</th>\n",
              "      <th>Method</th>\n",
              "      <th>Regionname</th>\n",
              "      <th>Rooms</th>\n",
              "      <th>Distance</th>\n",
              "      <th>Postcode</th>\n",
              "      <th>Bedroom2</th>\n",
              "      <th>Bathroom</th>\n",
              "      <th>Landsize</th>\n",
              "      <th>Lattitude</th>\n",
              "      <th>Longtitude</th>\n",
              "      <th>Propertycount</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>12167</th>\n",
              "      <td>u</td>\n",
              "      <td>S</td>\n",
              "      <td>Southern Metropolitan</td>\n",
              "      <td>1</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3182.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-37.85984</td>\n",
              "      <td>144.9867</td>\n",
              "      <td>13240.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6524</th>\n",
              "      <td>h</td>\n",
              "      <td>SA</td>\n",
              "      <td>Western Metropolitan</td>\n",
              "      <td>2</td>\n",
              "      <td>8.0</td>\n",
              "      <td>3016.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>193.0</td>\n",
              "      <td>-37.85800</td>\n",
              "      <td>144.9005</td>\n",
              "      <td>6380.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8413</th>\n",
              "      <td>h</td>\n",
              "      <td>S</td>\n",
              "      <td>Western Metropolitan</td>\n",
              "      <td>3</td>\n",
              "      <td>12.6</td>\n",
              "      <td>3020.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>555.0</td>\n",
              "      <td>-37.79880</td>\n",
              "      <td>144.8220</td>\n",
              "      <td>3755.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2919</th>\n",
              "      <td>u</td>\n",
              "      <td>SP</td>\n",
              "      <td>Northern Metropolitan</td>\n",
              "      <td>3</td>\n",
              "      <td>13.0</td>\n",
              "      <td>3046.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>265.0</td>\n",
              "      <td>-37.70830</td>\n",
              "      <td>144.9158</td>\n",
              "      <td>8870.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6043</th>\n",
              "      <td>h</td>\n",
              "      <td>S</td>\n",
              "      <td>Western Metropolitan</td>\n",
              "      <td>3</td>\n",
              "      <td>13.3</td>\n",
              "      <td>3020.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>673.0</td>\n",
              "      <td>-37.76230</td>\n",
              "      <td>144.8272</td>\n",
              "      <td>4217.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      Type Method             Regionname  ...  Lattitude  Longtitude  Propertycount\n",
              "12167    u      S  Southern Metropolitan  ...  -37.85984    144.9867        13240.0\n",
              "6524     h     SA   Western Metropolitan  ...  -37.85800    144.9005         6380.0\n",
              "8413     h      S   Western Metropolitan  ...  -37.79880    144.8220         3755.0\n",
              "2919     u     SP  Northern Metropolitan  ...  -37.70830    144.9158         8870.0\n",
              "6043     h      S   Western Metropolitan  ...  -37.76230    144.8272         4217.0\n",
              "\n",
              "[5 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7uykC3csN2he",
        "colab_type": "text"
      },
      "source": [
        "Em seguida, obtemos uma lista de todas as **variáveis categóricas nos dados de treinamento**.\n",
        "\n",
        "Fazemos isso verificando o **tipo de dados** (ou dtype) de cada coluna. O objeto dtype indica que uma coluna tem texto (há outras coisas que teoricamente poderiam ser, mas isso não é importante para nossos propósitos). Para esse conjunto de dados, as colunas com texto indicam variáveis categóricas."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hHVFO0IhNmIj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "370c5bea-8762-458e-b877-171698b9424e"
      },
      "source": [
        "# Obter lista de variáveis categóricas\n",
        "s = (X_train.dtypes == 'object')\n",
        "object_cols = list(s[s].index)\n",
        "\n",
        "print(\"Variáveis Categóricas:\")\n",
        "print(object_cols)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Variáveis Categóricas:\n",
            "['Type', 'Method', 'Regionname']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EwJd0qZhOMUD",
        "colab_type": "text"
      },
      "source": [
        "### Definir função para medir a qualidade de cada abordagem\n",
        "Criaremos uma função *score_dataset()* para comparar as três abordagens diferentes para lidar com variáveis categóricas. Esta função relata **o erro absoluto médio (MAE) de um modelo de floresta aleatório**. Em geral, queremos que o MAE seja o mais baixo possível!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ztWLIIiaOKUJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "# Função para comparar diferentes abordagens\n",
        "def score_dataset(X_train, X_valid, y_train, y_valid):\n",
        "    model = RandomForestRegressor(n_estimators=100, random_state=0)\n",
        "    model.fit(X_train, y_train)\n",
        "    preds = model.predict(X_valid)\n",
        "    return mean_absolute_error(y_valid, preds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "576z1KV5Omjz",
        "colab_type": "text"
      },
      "source": [
        "### 1) Descarte de variáveis categóricas\n",
        "Soltamos as colunas do objeto com o método *select_dtypes()*."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i2N0zCh0Ody4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "b25be33b-e7d1-4fba-f4ca-79f21a6247b3"
      },
      "source": [
        "drop_X_train = X_train.select_dtypes(exclude=['object'])\n",
        "drop_X_valid = X_valid.select_dtypes(exclude=['object'])\n",
        "\n",
        "print(\"MAE da Abordagem 1 (Descarte de variáveis categóricas):\")\n",
        "print(score_dataset(drop_X_train, drop_X_valid, y_train, y_valid))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MAE da Abordagem 1 (Descarte de variáveis categóricas):\n",
            "175703.48185157913\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UqHPGCnZOykn",
        "colab_type": "text"
      },
      "source": [
        "### 2) Codificação de etiqueta\n",
        "O *Scikit-learn* possui uma classe *LabelEncoder* que pode ser usada para obter codificações de etiquetas. Repetimos as variáveis categóricas e aplicamos o codificador de rótulo separadamente a cada coluna."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hMF77k2xOwGR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "238671f2-f3f1-4a99-845f-8f5646f71321"
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Faz uma cópia para evitar mudanças nos dados originais\n",
        "label_X_train = X_train.copy()\n",
        "label_X_valid = X_valid.copy()\n",
        "\n",
        "# Aplica o codificador de rótulos para cada coluna com dados categóricas\n",
        "label_encoder = LabelEncoder()\n",
        "for col in object_cols:\n",
        "    label_X_train[col] = label_encoder.fit_transform(X_train[col])\n",
        "    label_X_valid[col] = label_encoder.transform(X_valid[col])\n",
        "\n",
        "print(\"MAE da abordagem 2 (Codificação de etiqueta):\") \n",
        "print(score_dataset(label_X_train, label_X_valid, y_train, y_valid))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MAE da abordagem 2 (Codificação de etiqueta):\n",
            "165936.40548390493\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W9GGxHhyPAmM",
        "colab_type": "text"
      },
      "source": [
        "Na célula de código acima, para cada coluna, atribuímos aleatoriamente cada valor exclusivo a um número inteiro diferente. Essa é uma abordagem comum que é mais simples do que fornecer rótulos personalizados; no entanto, podemos esperar um aumento adicional no desempenho se fornecermos rótulos mais bem informados para todas as variáveis ordinais.\n",
        "\n",
        "### 3) Codificação One-hot\n",
        "Usamos a classe *OneHotEncoder *do *scikit-learn* para obter codificações únicas. Há vários parâmetros que podem ser usados para personalizar seu comportamento:\n",
        "\n",
        " - Definimos *handle_unknown = 'ignore'* para evitar erros quando os dados de validação contêm classes que não são representadas nos dados de treinamento;\n",
        " - A configuração *sparse = False* garante que as colunas codificadas sejam retornadas como uma matriz numpy (em vez de uma matriz esparsa). <br>\n",
        " \n",
        "Para usar o codificador, fornecemos apenas as colunas categóricas que queremos que sejam codificadas. Por exemplo, para codificar os dados de treinamento, fornecemos *X_train [object_cols]*. (*object_cols* na célula de código abaixo é uma lista dos nomes das colunas com dados categóricos e, portanto, *X_train [object_cols]* contém todos os dados categóricos no conjunto de treinamento.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QU-ZHD5xO9df",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "e8fe90c9-4689-456d-881b-39391291a949"
      },
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "\n",
        "# Aplica a codificador one-hot encoder em cada coluna om dados categóricos\n",
        "OH_encoder = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
        "OH_cols_train = pd.DataFrame(OH_encoder.fit_transform(X_train[object_cols]))\n",
        "OH_cols_valid = pd.DataFrame(OH_encoder.transform(X_valid[object_cols]))\n",
        "\n",
        "# One-hot encoding removed index; put it back\n",
        "OH_cols_train.index = X_train.index\n",
        "OH_cols_valid.index = X_valid.index\n",
        "\n",
        "# Remove categorical columns (will replace with one-hot encoding)\n",
        "num_X_train = X_train.drop(object_cols, axis=1)\n",
        "num_X_valid = X_valid.drop(object_cols, axis=1)\n",
        "\n",
        "# Add one-hot encoded columns to numerical features\n",
        "OH_X_train = pd.concat([num_X_train, OH_cols_train], axis=1)\n",
        "OH_X_valid = pd.concat([num_X_valid, OH_cols_valid], axis=1)\n",
        "\n",
        "print(\"MAE da abordagem 3 (Codificador One-Hot):\") \n",
        "print(score_dataset(OH_X_train, OH_X_valid, y_train, y_valid))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MAE da abordagem 3 (Codificador One-Hot):\n",
            "166089.4893009678\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ocToJNf2PWVI",
        "colab_type": "text"
      },
      "source": [
        "### Qual abordagem é a melhor?\n",
        "Nesse caso, o descarte das colunas categóricas (Abordagem 1) teve pior desempenho, uma vez que teve a maior pontuação no MAE. Quanto às outras duas abordagens, uma vez que as pontuações retornadas do MAE são tão próximas em valor, não parece haver nenhum benefício significativo para uma sobre a outra.\n",
        "\n",
        "Em geral, a codificação one-hot (Abordagem 3) geralmente apresenta melhor desempenho e a eliminação das colunas categóricas (Abordagem 1) geralmente apresenta pior desempenho, mas varia de acordo com o caso."
      ]
    }
  ]
}